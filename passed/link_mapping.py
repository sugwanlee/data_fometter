# import csv
# import os
# import uuid
# import mimetypes
# from datetime import datetime
# import requests
# from dotenv import load_dotenv
# from supabase import create_client, Client
# from typing import List, Dict, Any, Optional
# from formatter_config import BUCKET_CONFIGS  # formatter_config ì„¤ì • ì„í¬íŠ¸
# from urllib.parse import unquote  # URL ë””ì½”ë”©ì„ ìœ„í•´ ì¶”ê°€

# load_dotenv()

# # ğŸ”§ Supabase ì„¤ì •
# # Supabase í”„ë¡œì íŠ¸ URLê³¼ API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤
# SUPABASE_URL = os.getenv('SUPABASE_URL')
# SUPABASE_KEY = os.getenv('SUPABASE_KEY')
# PUBLIC_BUCKET = ['image', 'track/mp3', 'track/wav', 'business', 'other']  # ë²„í‚· ì´ë¦„ ëª©ë¡

# # íŒŒì¼ í˜•ì‹ë³„ ì—…ë¡œë“œ ê²½ë¡œ ë§¤í•‘
# FILE_TYPE_MAPPING = {
#     # ì´ë¯¸ì§€ íŒŒì¼
#     '.png': 'image',
#     '.jpg': 'image',
#     '.jfif': 'image',
    
#     # ì˜¤ë””ì˜¤ íŒŒì¼
#     '.mp3': 'track/mp3',
#     '.wav': 'track/wav',
    
#     # ë¬¸ì„œ íŒŒì¼
#     '.pdf': 'business',
# }

# # ê¸°ë³¸ ì—…ë¡œë“œ ê²½ë¡œ (ë§¤í•‘ë˜ì§€ ì•Šì€ íŒŒì¼ í˜•ì‹ìš©)
# DEFAULT_UPLOAD_PATH = 'other'

# # ì…ì¶œë ¥ CSV íŒŒì¼ ì„¤ì •
# INPUT_CSV = 'bubble_files.csv'  # ì›ë³¸ bubble.io URLì´ ìˆëŠ” CSV íŒŒì¼
# OUTPUT_CSV = 'updated_bubble_files.csv'  # ë³€í™˜ëœ URLì´ ì €ì¥ë  CSV íŒŒì¼

# # Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# # íŒŒì¼ ì¹´ìš´í„°ë¥¼ ì €ì¥í•  ì „ì—­ ë”•ì…”ë„ˆë¦¬
# file_counters = {}

# def get_next_file_number(table_name: str, column_name: str) -> int:
#     """
#     í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ì— ëŒ€í•œ ë‹¤ìŒ íŒŒì¼ ë²ˆí˜¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
#     Args:
#         table_name (str): í…Œì´ë¸” ì´ë¦„
#         column_name (str): ì»¬ëŸ¼ ì´ë¦„
        
#     Returns:
#         int: ë‹¤ìŒ íŒŒì¼ ë²ˆí˜¸
#     """
#     key = f"{table_name}_{column_name}"
#     if key not in file_counters:
#         file_counters[key] = 0
#     file_counters[key] += 1
#     return file_counters[key]

# def get_file_name(original_name: str, bucket_config: Dict[str, Any], row: Dict[str, Any], 
#                   table_name: str = None, column_name: str = None) -> str:
#     """
#     íŒŒì¼ ì´ë¦„ì„ ìƒì„±í•©ë‹ˆë‹¤. filename_patternì´ ìˆìœ¼ë©´ ì‚¬ìš©í•˜ê³ , 
#     ì—†ìœ¼ë©´ í…Œì´ë¸”ëª…_ì»¬ëŸ¼ëª…_ìˆœë²ˆ.í™•ì¥ì í˜•ì‹ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    
#     Args:
#         original_name (str): ì›ë³¸ íŒŒì¼ ì´ë¦„
#         bucket_config (Dict[str, Any]): ë²„í‚· ì„¤ì •
#         row (Dict[str, Any]): í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë°ì´í„° í–‰
#         table_name (str, optional): í…Œì´ë¸” ì´ë¦„
#         column_name (str, optional): ì»¬ëŸ¼ ì´ë¦„
        
#     Returns:
#         str: ìƒì„±ëœ íŒŒì¼ ì´ë¦„
#     """
#     # filename_patternì´ ìˆìœ¼ë©´ ì‚¬ìš©
#     if 'filename_pattern' in bucket_config:
#         try:
#             return bucket_config['filename_pattern'](row)
#         except:
#             pass
    
#     # filename_patternì´ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°
#     # ì›ë³¸ íŒŒì¼ì˜ í™•ì¥ì ì¶”ì¶œ
#     _, ext = os.path.splitext(original_name.lower())
#     if not ext and '?' in original_name:  # URLì— ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ê°€ ìˆëŠ” ê²½ìš°
#         ext = os.path.splitext(original_name.split('?')[0].lower())[1]
    
#     if not ext:  # í™•ì¥ìê°€ ì—†ëŠ” ê²½ìš° MIME íƒ€ì…ìœ¼ë¡œ í™•ì¥ì ì¶”ì •
#         mime_type = mimetypes.guess_type(original_name)[0]
#         if mime_type:
#             ext = mimetypes.guess_extension(mime_type) or '.bin'
#         else:
#             ext = '.bin'
    
#     # í…Œì´ë¸”ëª…ê³¼ ì»¬ëŸ¼ëª…ì´ ì œê³µëœ ê²½ìš° ì‚¬ìš©
#     if table_name and column_name:
#         file_number = get_next_file_number(table_name, column_name)
#         return f"{table_name}_{column_name}_{file_number}{ext}"
    
#     # í…Œì´ë¸”ëª…ê³¼ ì»¬ëŸ¼ëª…ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ í˜•ì‹ ì‚¬ìš©
#     timestamp = int(datetime.now().timestamp() * 1000)
#     unique_id = str(uuid.uuid4())
#     return f"{timestamp}_{unique_id}{ext}"

# async def upload_file_to_supabase(file_content: bytes, original_name: str, mime_type: str, 
#                                 table_name: str, column_name: str, row: Dict[str, Any]) -> str:
#     """
#     íŒŒì¼ì„ Supabase ìŠ¤í† ë¦¬ì§€ì— ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    
#     Args:
#         file_content (bytes): ì—…ë¡œë“œí•  íŒŒì¼ì˜ ë°”ì´ë„ˆë¦¬ ë‚´ìš©
#         original_name (str): ì›ë³¸ íŒŒì¼ ì´ë¦„
#         mime_type (str): íŒŒì¼ì˜ MIME íƒ€ì…
#         table_name (str): í…Œì´ë¸” ì´ë¦„
#         column_name (str): ì»¬ëŸ¼ ì´ë¦„
#         row (Dict[str, Any]): í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë°ì´í„° í–‰
        
#     Returns:
#         str: Supabaseì— ì—…ë¡œë“œëœ íŒŒì¼ì˜ ê²½ë¡œ (ë²„í‚· ì´ë¦„ í¬í•¨)
#     """
#     bucket_config = get_bucket_config(table_name, column_name)
#     if not bucket_config:
#         raise Exception(f"ë²„í‚· ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {table_name}.{column_name}")
    
#     bucket_name = bucket_config['name']
#     storage_path = bucket_config['path']
    
#     try:
#         # ì²« ë²ˆì§¸ ì‹œë„: ì›ë³¸ íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ì—…ë¡œë“œ
#         file_name = original_name.split('/')[-1]
#         upload_path = f"{storage_path}/{file_name}"
        
#         try:
#             # ê¸°ì¡´ íŒŒì¼ì´ ìˆë‹¤ë©´ ì‚­ì œ
#             try:
#                 supabase.storage.from_(bucket_name).remove([upload_path])
#             except:
#                 pass  # íŒŒì¼ì´ ì—†ì–´ë„ ë¬´ì‹œ
            
#             # ìƒˆë¡œìš´ íŒŒì¼ ì—…ë¡œë“œ
#             result = supabase.storage.from_(bucket_name).upload(
#                 upload_path,
#                 file_content,
#                 {"content-type": mime_type}
#             )
#             return f"{bucket_name}/{upload_path}"  # ë²„í‚· ì´ë¦„ê³¼ ê²½ë¡œ ì¡°í•©
#         except Exception as e:
#             if '400' in str(e):  # 400 ì—ëŸ¬ ë°œìƒ ì‹œ filename_patternìœ¼ë¡œ ì¬ì‹œë„
#                 file_name = get_file_name(original_name, bucket_config, row, table_name, column_name)
#                 upload_path = f"{storage_path}/{file_name}"
                
#                 # ê¸°ì¡´ íŒŒì¼ì´ ìˆë‹¤ë©´ ì‚­ì œ
#                 try:
#                     supabase.storage.from_(bucket_name).remove([upload_path])
#                 except:
#                     pass  # íŒŒì¼ì´ ì—†ì–´ë„ ë¬´ì‹œ
                
#                 # ìƒˆë¡œìš´ íŒŒì¼ ì—…ë¡œë“œ
#                 result = supabase.storage.from_(bucket_name).upload(
#                     upload_path,
#                     file_content,
#                     {"content-type": mime_type}
#                 )
#                 return f"{bucket_name}/{upload_path}"  # ë²„í‚· ì´ë¦„ê³¼ ê²½ë¡œ ì¡°í•©
#             raise e
            
#     except Exception as e:
#         raise Exception(f"Upload failed: {str(e)}")

# def get_public_url(path: str) -> str:
#     """
#     Supabase ìŠ¤í† ë¦¬ì§€ì˜ íŒŒì¼ì— ëŒ€í•œ ê³µê°œ URLì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
#     Args:
#         path (str): Supabase ìŠ¤í† ë¦¬ì§€ ë‚´ íŒŒì¼ ê²½ë¡œ (ë²„í‚· ì´ë¦„ í¬í•¨)
        
#     Returns:
#         str: íŒŒì¼ì˜ ê³µê°œ ì ‘ê·¼ URL
#     """
#     # ê²½ë¡œì—ì„œ ë²„í‚· ì´ë¦„ê³¼ íŒŒì¼ ê²½ë¡œ ë¶„ë¦¬
#     parts = path.split('/', 1)
#     bucket = parts[0]
#     file_path = parts[1] if len(parts) > 1 else ''
    
#     return f"{SUPABASE_URL}/storage/v1/object/public/{bucket}/{file_path}"

# def find_table_for_column(column_name: str) -> Optional[str]:
#     """
#     ì£¼ì–´ì§„ ì»¬ëŸ¼ì´ ì–´ëŠ í…Œì´ë¸”ì— ì†í•˜ëŠ”ì§€ ì°¾ìŠµë‹ˆë‹¤.
    
#     Args:
#         column_name (str): ì°¾ì„ ì»¬ëŸ¼ ì´ë¦„
        
#     Returns:
#         Optional[str]: í…Œì´ë¸” ì´ë¦„. ì°¾ì§€ ëª»í•œ ê²½ìš° None
#     """
#     for table_name, config in BUCKET_CONFIGS.items():
#         if column_name in config:
#             return table_name
#     return None

# def is_file_url(value: str) -> bool:
#     """
#     ì£¼ì–´ì§„ ê°’ì´ bubble.io íŒŒì¼ URLì¸ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    
#     Args:
#         value (str): í™•ì¸í•  URL ë¬¸ìì—´
        
#     Returns:
#         bool: bubble.io URLì´ë©´ True, ì•„ë‹ˆë©´ False
#     """
#     return isinstance(value, str) and 'bubble.io' in value

# def normalize_url(url: str) -> str:
#     """
#     URLì„ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜
#     - '//'ë¡œ ì‹œì‘í•˜ëŠ” URLì„ 'https://'ë¡œ ë³€í™˜
#     - URL ì¸ì½”ë”©ëœ ë¬¸ìë¥¼ ë””ì½”ë”©
    
#     Args:
#         url (str): ì •ê·œí™”í•  URL
        
#     Returns:
#         str: ì •ê·œí™”ëœ URL
#     """
#     # URL ë””ì½”ë”©
#     decoded_url = unquote(url)
    
#     # '//'ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° 'https:'ë¥¼ ì¶”ê°€
#     if decoded_url.startswith('//'):
#         return f'https:{decoded_url}'
#     # 'http://' ë˜ëŠ” 'https://'ë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ” ê²½ìš° 'https://'ë¥¼ ì¶”ê°€
#     elif not decoded_url.startswith(('http://', 'https://')):
#         return f'https://{decoded_url}'
#     return decoded_url

# async def process_csv():
#     """
#     CSV íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
#     """
#     if not os.path.exists(INPUT_CSV):
#         raise Exception(f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {INPUT_CSV}")
            
#     # CSV íŒŒì¼ ì½ê¸°
#     rows = []
#     with open(INPUT_CSV, 'r', encoding='utf-8') as file:
#         reader = csv.DictReader(file)
#         rows = list(reader)
            
#     if not rows:
#         print("âŒ CSV íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
#         return
            
#     print(f"ğŸ” ì´ {len(rows)}ê±´ ì²˜ë¦¬ ì‹œì‘")
    
#     # ì²˜ë¦¬í•  ì»¬ëŸ¼ ì°¾ê¸°
#     columns = rows[0].keys()
#     file_columns = [
#         col for col in columns 
#         if any(is_file_url(row[col]) for row in rows)
#     ]
    
#     if not file_columns:
#         print("âŒ bubble.io URLì„ í¬í•¨í•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
#         return
    
#     print(f"âœ… íŒŒì¼ URL ì»¬ëŸ¼: {', '.join(file_columns)}")
    
#     # ê° í–‰ì˜ URL ì²˜ë¦¬
#     for row in rows:
#         for col in file_columns:
#             raw_url = row[col]
#             if not is_file_url(raw_url):
#                 continue
            
#             # í…Œì´ë¸” ì°¾ê¸°
#             table_name = None
#             for t_name, t_config in BUCKET_CONFIGS.items():
#                 if col in t_config:
#                     table_name = t_name
#                     break
            
#             if not table_name:
#                 print(f"âš ï¸ ì»¬ëŸ¼ '{col}'ì— ëŒ€í•œ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
#                 continue
                
#             file_url = normalize_url(raw_url)
#             original_name = file_url.split('/')[-1]
            
#             try:
#                 response = requests.get(file_url)
#                 response.raise_for_status()
                
#                 mime_type = mimetypes.guess_type(original_name)[0] or 'application/octet-stream'
#                 storage_path = await upload_file_to_supabase(
#                     response.content,
#                     original_name,
#                     mime_type,
#                     table_name,
#                     col,
#                     row
#                 )
#                 public_url = get_public_url(storage_path)
#                 row[col] = public_url
#                 print(f"ğŸ“¤ ì—…ë¡œë“œ ì™„ë£Œ: {original_name}")
                
#             except Exception as e:
#                 print(f"âš ï¸ ì‹¤íŒ¨ ({file_url}): {str(e)}")
                    
#     # ë³€í™˜ëœ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥
#     with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as file:
#         writer = csv.DictWriter(file, fieldnames=columns)
#         writer.writeheader()
#         writer.writerows(rows)
            
#     print(f"ğŸ‰ ì™„ë£Œ! ì—…ë°ì´íŠ¸ëœ CSV ì €ì¥ë¨ â†’ {OUTPUT_CSV}")

# if __name__ == "__main__":
#     import asyncio
#     asyncio.run(process_csv())
