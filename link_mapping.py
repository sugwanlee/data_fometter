import csv
import os
import uuid
import mimetypes
from datetime import datetime
import requests
from dotenv import load_dotenv
from supabase import create_client, Client
from typing import List, Dict, Any, Optional
from formatter_config import BUCKET_CONFIGS  # formatter_config ì„¤ì • ì„í¬íŠ¸
from urllib.parse import unquote  # URL ë””ì½”ë”©ì„ ìœ„í•´ ì¶”ê°€

load_dotenv()

# ğŸ”§ Supabase ì„¤ì •
# Supabase í”„ë¡œì íŠ¸ URLê³¼ API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')
PUBLIC_BUCKET = ['image', 'track/mp3', 'track/wav', 'business', 'other']  # ë²„í‚· ì´ë¦„ ëª©ë¡

# íŒŒì¼ í˜•ì‹ë³„ ì—…ë¡œë“œ ê²½ë¡œ ë§¤í•‘
FILE_TYPE_MAPPING = {
    # ì´ë¯¸ì§€ íŒŒì¼
    '.png': 'image',
    '.jpg': 'image',
    '.jfif': 'image',
    
    # ì˜¤ë””ì˜¤ íŒŒì¼
    '.mp3': 'track/mp3',
    '.wav': 'track/wav',
    
    # ë¬¸ì„œ íŒŒì¼
    '.pdf': 'business',
}

# ê¸°ë³¸ ì—…ë¡œë“œ ê²½ë¡œ (ë§¤í•‘ë˜ì§€ ì•Šì€ íŒŒì¼ í˜•ì‹ìš©)
DEFAULT_UPLOAD_PATH = 'other'

# ì…ì¶œë ¥ CSV íŒŒì¼ ì„¤ì •
INPUT_CSV = 'bubble_files.csv'  # ì›ë³¸ bubble.io URLì´ ìˆëŠ” CSV íŒŒì¼
OUTPUT_CSV = 'updated_bubble_files.csv'  # ë³€í™˜ëœ URLì´ ì €ì¥ë  CSV íŒŒì¼

# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

def is_file_url(value: str) -> bool:
    """
    ì£¼ì–´ì§„ ê°’ì´ bubble.io íŒŒì¼ URLì¸ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        value (str): í™•ì¸í•  URL ë¬¸ìì—´
        
    Returns:
        bool: bubble.io URLì´ë©´ True, ì•„ë‹ˆë©´ False
    """
    return isinstance(value, str) and 'bubble.io' in value

def normalize_url(url: str) -> str:
    """
    URLì„ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜
    - '//'ë¡œ ì‹œì‘í•˜ëŠ” URLì„ 'https://'ë¡œ ë³€í™˜
    - URL ì¸ì½”ë”©ëœ ë¬¸ìë¥¼ ë””ì½”ë”©
    
    Args:
        url (str): ì •ê·œí™”í•  URL
        
    Returns:
        str: ì •ê·œí™”ëœ URL
    """
    # URL ë””ì½”ë”©
    decoded_url = unquote(url)
    
    # '//'ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° 'https:'ë¥¼ ì¶”ê°€
    if decoded_url.startswith('//'):
        return f'https:{decoded_url}'
    # 'http://' ë˜ëŠ” 'https://'ë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ” ê²½ìš° 'https://'ë¥¼ ì¶”ê°€
    elif not decoded_url.startswith(('http://', 'https://')):
        return f'https://{decoded_url}'
    return decoded_url

def get_bucket_config(table_name: str, column_name: str) -> Dict[str, Any]:
    """
    í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ì— í•´ë‹¹í•˜ëŠ” ë²„í‚· ì„¤ì •ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        table_name (str): í…Œì´ë¸” ì´ë¦„
        column_name (str): ì»¬ëŸ¼ ì´ë¦„
        
    Returns:
        Dict[str, Any]: ë²„í‚· ì„¤ì • ì •ë³´
    """
    table_config = BUCKET_CONFIGS.get(table_name, {})
    return table_config.get(column_name, {})

def get_file_name(original_name: str, bucket_config: Dict[str, Any], row: Dict[str, Any]) -> str:
    """
    íŒŒì¼ ì´ë¦„ì„ ìƒì„±í•©ë‹ˆë‹¤. filename_patternì´ ìˆìœ¼ë©´ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ê¸°ë³¸ íŒ¨í„´ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Args:
        original_name (str): ì›ë³¸ íŒŒì¼ ì´ë¦„
        bucket_config (Dict[str, Any]): ë²„í‚· ì„¤ì •
        row (Dict[str, Any]): í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë°ì´í„° í–‰
        
    Returns:
        str: ìƒì„±ëœ íŒŒì¼ ì´ë¦„
    """
    if 'filename_pattern' in bucket_config:
        try:
            return bucket_config['filename_pattern'](row)
        except:
            pass
    
    timestamp = int(datetime.now().timestamp() * 1000)
    unique_id = str(uuid.uuid4())
    sanitized_name = original_name.replace(' ', '_')
    return f"{timestamp}_{unique_id}_{sanitized_name}"

async def upload_file_to_supabase(file_content: bytes, original_name: str, mime_type: str, 
                                table_name: str, column_name: str, row: Dict[str, Any]) -> str:
    """
    íŒŒì¼ì„ Supabase ìŠ¤í† ë¦¬ì§€ì— ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        file_content (bytes): ì—…ë¡œë“œí•  íŒŒì¼ì˜ ë°”ì´ë„ˆë¦¬ ë‚´ìš©
        original_name (str): ì›ë³¸ íŒŒì¼ ì´ë¦„
        mime_type (str): íŒŒì¼ì˜ MIME íƒ€ì…
        table_name (str): í…Œì´ë¸” ì´ë¦„
        column_name (str): ì»¬ëŸ¼ ì´ë¦„
        row (Dict[str, Any]): í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë°ì´í„° í–‰
        
    Returns:
        str: Supabaseì— ì—…ë¡œë“œëœ íŒŒì¼ì˜ ê²½ë¡œ (ë²„í‚· ì´ë¦„ í¬í•¨)
    """
    bucket_config = get_bucket_config(table_name, column_name)
    if not bucket_config:
        raise Exception(f"ë²„í‚· ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {table_name}.{column_name}")
    
    bucket_name = bucket_config['name']
    storage_path = bucket_config['path']
    
    try:
        # ì²« ë²ˆì§¸ ì‹œë„: ì›ë³¸ íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ì—…ë¡œë“œ
        file_name = original_name.split('/')[-1]
        upload_path = f"{storage_path}/{file_name}"
        
        try:
            # ê¸°ì¡´ íŒŒì¼ì´ ìˆë‹¤ë©´ ì‚­ì œ
            try:
                supabase.storage.from_(bucket_name).remove([upload_path])
            except:
                pass  # íŒŒì¼ì´ ì—†ì–´ë„ ë¬´ì‹œ
            
            # ìƒˆë¡œìš´ íŒŒì¼ ì—…ë¡œë“œ
            result = supabase.storage.from_(bucket_name).upload(
                upload_path,
                file_content,
                {"content-type": mime_type}
            )
            return f"{bucket_name}/{upload_path}"  # ë²„í‚· ì´ë¦„ê³¼ ê²½ë¡œ ì¡°í•©
        except Exception as e:
            if '400' in str(e):  # 400 ì—ëŸ¬ ë°œìƒ ì‹œ filename_patternìœ¼ë¡œ ì¬ì‹œë„
                file_name = get_file_name(original_name, bucket_config, row)
                upload_path = f"{storage_path}/{file_name}"
                
                # ê¸°ì¡´ íŒŒì¼ì´ ìˆë‹¤ë©´ ì‚­ì œ
                try:
                    supabase.storage.from_(bucket_name).remove([upload_path])
                except:
                    pass  # íŒŒì¼ì´ ì—†ì–´ë„ ë¬´ì‹œ
                
                # ìƒˆë¡œìš´ íŒŒì¼ ì—…ë¡œë“œ
                result = supabase.storage.from_(bucket_name).upload(
                    upload_path,
                    file_content,
                    {"content-type": mime_type}
                )
                return f"{bucket_name}/{upload_path}"  # ë²„í‚· ì´ë¦„ê³¼ ê²½ë¡œ ì¡°í•©
            raise e
            
    except Exception as e:
        raise Exception(f"Upload failed: {str(e)}")

def get_public_url(path: str) -> str:
    """
    Supabase ìŠ¤í† ë¦¬ì§€ì˜ íŒŒì¼ì— ëŒ€í•œ ê³µê°œ URLì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        path (str): Supabase ìŠ¤í† ë¦¬ì§€ ë‚´ íŒŒì¼ ê²½ë¡œ (ë²„í‚· ì´ë¦„ í¬í•¨)
        
    Returns:
        str: íŒŒì¼ì˜ ê³µê°œ ì ‘ê·¼ URL
    """
    # ê²½ë¡œì—ì„œ ë²„í‚· ì´ë¦„ê³¼ íŒŒì¼ ê²½ë¡œ ë¶„ë¦¬
    parts = path.split('/', 1)
    bucket = parts[0]
    file_path = parts[1] if len(parts) > 1 else ''
    
    return f"{SUPABASE_URL}/storage/v1/object/public/{bucket}/{file_path}"

def find_table_for_column(column_name: str) -> Optional[str]:
    """
    ì£¼ì–´ì§„ ì»¬ëŸ¼ì´ ì–´ëŠ í…Œì´ë¸”ì— ì†í•˜ëŠ”ì§€ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        column_name (str): ì°¾ì„ ì»¬ëŸ¼ ì´ë¦„
        
    Returns:
        Optional[str]: í…Œì´ë¸” ì´ë¦„. ì°¾ì§€ ëª»í•œ ê²½ìš° None
    """
    for table_name, config in BUCKET_CONFIGS.items():
        if column_name in config:
            return table_name
    return None

async def process_csv():
    """
    CSV íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    1. CSV íŒŒì¼ ì½ê¸°
    2. bubble.io URL ì°¾ê¸°
    3. ê° URLì˜ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ Supabaseì— ì—…ë¡œë“œ
    4. ìƒˆë¡œìš´ URLë¡œ êµì²´
    5. ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥
    """
    rows: List[Dict[str, Any]] = []
    
    # CSV íŒŒì¼ ì½ê¸°
    with open(INPUT_CSV, 'r', encoding='utf-8') as file:
        reader = csv.DictReader(file)
        rows = list(reader)
    
    print(f"ğŸ” ì´ {len(rows)}ê±´ ì²˜ë¦¬ ì‹œì‘")
    
    if not rows:
        print("âŒ CSV íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return
    
    columns = rows[0].keys()
    
    # í…Œì´ë¸” ì´ë¦„ í™•ì¸ (CSV íŒŒì¼ëª… ë˜ëŠ” ì‚¬ìš©ì ì…ë ¥ í•„ìš”)
    table_name = input("í…Œì´ë¸” ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”: ").lower()
    if table_name not in BUCKET_CONFIGS:
        print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸”ì…ë‹ˆë‹¤: {table_name}")
        return
    
    # ì²˜ë¦¬í•  ì»¬ëŸ¼ ì°¾ê¸°
    valid_columns = BUCKET_CONFIGS[table_name].keys()
    file_columns = [col for col in columns if col in valid_columns]
    
    if not file_columns:
        print("âŒ ì²˜ë¦¬í•  ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… ì²˜ë¦¬í•  ì»¬ëŸ¼: {', '.join(file_columns)}")
    
    # ê° í–‰ì˜ URL ì²˜ë¦¬
    for row in rows:
        for col in file_columns:
            raw_url = row[col]
            if not is_file_url(raw_url):
                continue
            
            # URL ì •ê·œí™” ë° íŒŒì¼ëª… ì¶”ì¶œ
            file_url = normalize_url(raw_url)
            original_name = file_url.split('/')[-1]
            
            try:
                # bubble.ioì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                response = requests.get(file_url)
                response.raise_for_status()
                
                # íŒŒì¼ì˜ MIME íƒ€ì… í™•ì¸
                mime_type = mimetypes.guess_type(original_name)[0] or 'application/octet-stream'
                
                # Supabaseì— íŒŒì¼ ì—…ë¡œë“œ
                storage_path = await upload_file_to_supabase(
                    response.content,
                    original_name,
                    mime_type,
                    table_name,
                    col,
                    row
                )
                # ìƒˆë¡œìš´ ê³µê°œ URL ìƒì„±
                public_url = get_public_url(storage_path)
                
                # ì›ë³¸ URLì„ ìƒˆë¡œìš´ URLë¡œ êµì²´
                row[col] = public_url
                print(f"ğŸ“¤ ì—…ë¡œë“œ ì™„ë£Œ: {original_name}")
                
            except Exception as e:
                print(f"âš ï¸ ì‹¤íŒ¨ ({file_url}): {str(e)}")
    
    # ë³€í™˜ëœ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥
    with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as file:
        writer = csv.DictWriter(file, fieldnames=columns)
        writer.writeheader()
        writer.writerows(rows)
    
    print(f"ğŸ‰ ì™„ë£Œ! ì—…ë°ì´íŠ¸ëœ CSV ì €ì¥ë¨ â†’ {OUTPUT_CSV}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(process_csv())
