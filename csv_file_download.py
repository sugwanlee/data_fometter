import csv
import os
import requests
from typing import List, Dict, Any
import asyncio
from datetime import datetime
from tqdm import tqdm
from urllib.parse import unquote

def is_bubble_url(value: str) -> bool:
    """
    ì£¼ì–´ì§„ ê°’ì´ bubble.io íŒŒì¼ URLì¸ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        value (str): í™•ì¸í•  URL ë¬¸ìì—´
        
    Returns:
        bool: bubble.io URLì´ë©´ True, ì•„ë‹ˆë©´ False
    """
    return isinstance(value, str) and 'bubble.io' in value

def normalize_url(url: str) -> str:
    """
    URLì„ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜
    - '//'ë¡œ ì‹œì‘í•˜ëŠ” URLì„ 'https://'ë¡œ ë³€í™˜
    
    Args:
        url (str): ì •ê·œí™”í•  URL
        
    Returns:
        str: ì •ê·œí™”ëœ URL
    """
    # URL ë””ì½”ë”©
    decoded_url = unquote(url)
    
    # '//'ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° 'https:'ë¥¼ ì¶”ê°€
    if decoded_url.startswith('//'):
        return f'https:{decoded_url}'
    # 'http://' ë˜ëŠ” 'https://'ë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ” ê²½ìš° 'https://'ë¥¼ ì¶”ê°€
    elif not decoded_url.startswith(('http://', 'https://')):
        return f'https://{decoded_url}'
    return decoded_url

def get_file_name(url: str) -> str:
    """
    URLì—ì„œ íŒŒì¼ ê²½ë¡œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        url (str): íŒŒì¼ URL
        
    Returns:
        str: íŒŒì¼ ê²½ë¡œ
    """
    # URL ë””ì½”ë”©
    decoded_url = unquote(url)
    
    # bubble.io ë„ë©”ì¸ ì´í›„ì˜ ê²½ë¡œë¥¼ ì¶”ì¶œ
    path = decoded_url.split('.bubble.io/')[-1]
    if not path:
        return decoded_url.split('/')[-1]
    
    return path

async def download_file(url: str, save_dir: str) -> bool:
    """
    íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        url (str): ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ì˜ URL
        save_dir (str): íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
        
    Returns:
        bool: ë‹¤ìš´ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # URL ì •ê·œí™”
        normalized_url = normalize_url(url)
        file_path = get_file_name(normalized_url)
        save_path = os.path.join(save_dir, file_path)
        
        # íŒŒì¼ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŒŒì¼ì¸ ê²½ìš° ìŠ¤í‚µ
        if os.path.exists(save_path):
            print(f"âš ï¸ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {file_path}")
            return False
        
        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        response = requests.get(normalized_url, stream=True)
        response.raise_for_status()
        
        # íŒŒì¼ ì €ì¥
        with open(save_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        
        print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file_path}")
        return True
        
    except Exception as e:
        print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({url}): {str(e)}")
        return False

async def process_csv(csv_path: str):
    """
    CSV íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    
    Args:
        csv_path (str): ì²˜ë¦¬í•  CSV íŒŒì¼ ê²½ë¡œ
    """
    if not os.path.exists(csv_path):
        raise Exception(f"CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
    
    # CSV íŒŒì¼ëª… ì¶”ì¶œ (í™•ì¥ì ì œì™¸)
    csv_name = os.path.splitext(os.path.basename(csv_path))[0]
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    save_dir = f"{csv_name}_{timestamp}"
    os.makedirs(save_dir, exist_ok=True)
    
    # CSV íŒŒì¼ ì½ê¸°
    rows = []
    with open(csv_path, 'r', encoding='utf-8') as file:
        reader = csv.DictReader(file)
        rows = list(reader)
    
    if not rows:
        print("âŒ CSV íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return
    
    # bubble.io URLì´ í¬í•¨ëœ ì»¬ëŸ¼ ì°¾ê¸°
    columns = rows[0].keys()
    file_columns = [
        col for col in columns 
        if any(is_bubble_url(row[col]) for row in rows)
    ]
    
    if not file_columns:
        print("âŒ bubble.io URLì„ í¬í•¨í•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ” ì´ {len(rows)}ê±´ì˜ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
    print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {os.path.abspath(save_dir)}")
    print(f"ğŸ” ì²˜ë¦¬í•  ì»¬ëŸ¼: {', '.join(file_columns)}")
    
    # ì „ì²´ URL ìˆ˜ ê³„ì‚°
    total_urls = sum(1 for row in rows for col in file_columns if is_bubble_url(row[col]))
    success_count = 0
    
    # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ tqdm ì´ˆê¸°í™”
    with tqdm(total=total_urls, desc="ë‹¤ìš´ë¡œë“œ ì§„í–‰ë¥ ") as pbar:
        # ê° í–‰ì˜ URL ì²˜ë¦¬
        for row in rows:
            for col in file_columns:
                url = row[col]
                if not is_bubble_url(url):
                    continue
                
                if await download_file(url, save_dir):
                    success_count += 1
                pbar.update(1)
    
    print(f"\nğŸ‰ ì‘ì—… ì™„ë£Œ!")
    print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {total_urls - success_count}ê°œ")
    print(f"ğŸ“ ë‹¤ìš´ë¡œë“œ ê²½ë¡œ: {os.path.abspath(save_dir)}")

def main():
    """
    ë©”ì¸ í•¨ìˆ˜
    """
    # CSV íŒŒì¼ ê²½ë¡œ ì…ë ¥ ë°›ê¸°
    csv_path = input("CSV íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    
    try:
        # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
        asyncio.run(process_csv(csv_path))
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main()
